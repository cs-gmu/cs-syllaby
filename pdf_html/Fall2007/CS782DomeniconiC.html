<html>
<body BACKGROUND="./paper.gif">
<center>
<h1>
<h2><font color=blue>
Fall 2007: Machine Learning [CS782]
</font></h2>
</h1>
</center>

<font color=red>
</font> 

<ul>
<li>
     <FONT SIZE=+1><b>Instructor</b></FONT>:
     Carlotta Domeniconi, Rm 449 ST2, carlotta@ise.gmu.edu
</li>
</ul>


<ul>
<li>
     <FONT SIZE=+1><b>Prerequisites</b></FONT>: 
     CS 681 or CS 687 or CS 688 or permission of instructor.
     Some programming experience is expected.  
     Students should be familiar with
     basic probability and statistics concepts, linear algebra, optimization, and multivariate
     calculus. 
  
</li>
</ul>


<ul>
<li>
     <FONT SIZE=+1><b>Time</b></FONT>:
     We meet in IH 206, R 7:20pm - 10:00pm
</li>
</ul>


<ul>
<li>

      <FONT SIZE=+1><b>Textbook</b></FONT>:
     <blockquote>
     <li> C. M. Bishop <em>Pattern Recognition and Machine Learning</em>,
          Springer, 2006. 
          <br>
          <a href="http://research.microsoft.com/~cmbishop/PRML/">
            Book's companion website</a> <br>
     </blockquote> 
     </ul>
     </li>
      
     <ul>
     <li> 
     <FONT SIZE=+1><b>Useful material</b></FONT SIZE=+1>
     <blockquote> 
     <li> 
          <a href="http://www.ise.gmu.edu/~carlotta/teaching/INFS-795-s06/readings/linalgSMallatReview.pdf">
           Overview on Linear Algebra</a> <br>
     </li>

     </blockquote>


     </ul>

<p>
     <FONT SIZE=+1><b>General Description and Preliminary List of Topics</b></FONT SIZE=+1>: <br>
        Machine learning is concerned with the design of computer programs that can 
        improve their performance based on experience.  
        The course covers key algorithms and theory at the core of machine learning.
        Particular emphasis will be given to the statistical learning aspects of the field.
        Topics include:
        decision theory, Bayesian theory, curse of dimensionality, linear and non-linear 
        dimensionality reduction techniques, 
        classification, nearest neighbor methods, decision trees, clustering,  
        kernel methods, ensemble methods, semi-supervised learning.       

        <br>
      
     <p>
<FONT SIZE=+1><b>Course Format</b></FONT SIZE=+1>: <br> 
     Lectures by the instructor. Besides material from the textbook, topics not discussed in the book may also be
     covered.
     Research papers and handouts of material not covered in the book will
     be made available. 
     Grading will be based on homework assignments, 
     exams, and a project. Homeworks will require 
     some programming.

     






